Отлично, я подготовлю подробное и поэтапное техническое руководство по созданию победоносного прототипа Longevity Predictor, полностью соответствующее вашему техническому заданию.

В нём я пошагово опишу весь процесс: от архитектуры и агентов до визуализации, валидации, объяснимости и UX, включая конкретные алгоритмы, примеры запросов, схемы данных, инструменты и стратегии демонстрации.

Скоро вернусь с результатами.


# Longevity Predictor: проектирование выигрышного прототипа

## Шаг 1: Анализ технического задания

* **Цель системы:** ежедневно собирать информацию о продлении жизни (aging, longevity) из различных источников и выдавать исследователям и инвесторам приоритетные задачи с обоснованием. Целевая аудитория – учёные, стартапы, инвесторы в области геронтологии.
* **Ключевые компоненты (ожидаемые результаты):** мультисервисный парсер (PubMed, bioRxiv, WIPO, USPTO, экономические и новостные источники), тематическая классификация задач, модель приоритезации (ранжирования) с объяснениями, метрика уверенности (confidence score), интерфейс (web/telegram/CLI), тестовый датасет, документация (README/PDF с архитектурой и потоками данных).
* **Критерии оценки:**

  * *Точность и обоснованность приоритезации:* каждое предложение должно подкрепляться источниками, демонстрируя логические связи и ссылки на актуальную литературу.
  * *Полнота и разнообразие источников:* система должна учитывать научные статьи, препринты, патенты, отчёты, новости – разного рода данные (научные, патентные, экономические).
  * *Объяснимость и прозрачность:* модель должна показывать источники информации, выдавать confidence score и логическое обоснование выбора.
  * *Архитектура и масштабируемость:* модульный дизайн (на другие области, языки, источники), способность легко добавлять новые источники или типы данных.
  * *Демонстрация / UX:* простой, интуитивный интерфейс (например, телеграм-бот), визуализация (граф задач/знаний), понятная выдача (свиток отчёта с цитатами, графики активности).
* **Неявные требования:** поддержка многоязычности и разных регионов (можно использовать авто-перевод при необходимости), объяснимость результатов (ссылки на конкретные публикации и ключевые показатели), производительность (обновление раз в сутки, быстрое ранжирование), структурированность хранения данных.

## Шаг 2: Архитектура системы – модульные агенты

Предлагается **агентно-ориентированная архитектура** из трёх основных модулей (агентов) с очередями или асинхронным взаимодействием:

* **Агент «Сбор и фильтрация данных» (Data Ingestion Agent):**

  * *Роль:* агрегирует данные из разных источников (научные базы, патенты, отчёты, новости).
  * *Вход:* расписание или триггер «каждый день», запросы к API/скрейпинг.
  * *Выход:* нормализованные документы (JSON) с полями (источник, тип, заголовок, аннотация, дата, язык, URL/ID).
  * *Логика:* использует API и парсеры (см. Шаг 3). Фильтрует дубли, нерелевант по контексту («aging» в небиомедицинском смысле).
  * *Инструменты:* Python (requests, BeautifulSoup), Biopython (Entrez) для PubMed, официальные API для bioRxiv, USPTO/WIPO (PatentsView/Lens API), NewsAPI или RSS, загрузка CSV/JSON (World Bank, OECD). Возможно использование LlamaIndex для индексирования сбора.
  * *Взаимодействие:* складывает результаты в базу (например, Pinecone/Chroma для векторов + реляционную/JSON-базу). Сигнализирует очереди для дальнейшей обработки (например, очередь RabbitMQ или Pub/Sub).

* **Агент «Классификация и ранжирование» (Analysis Agent):**

  * *Роль:* обрабатывает собранные документы, извлекает из них ключевые темы/задачи и присваивает приоритет.
  * *Вход:* новые документы из агента 1 (их тексты/метаданные).
  * *Выход:* список тем/задач с оценками (зрелость, импакт, confidence).
  * *Логика:*

    1. **Извлечение тем и задач:** объединяет текст (заголовок+абстракт) из каждого документа, применяет NLP (названия, NER, ключевые слова). Можно использовать scispaCy (научные сущности), PubTator, LLM (GPT-4/Mixtral) или topic modeling (LDA/BERTopic) для генерации списка тем («сенолитики», «восстановление теломер», «иммунный надзор»).
    2. **Классификация по направлениям:** тематический классификатор (например, обученный LLM или многомодальный кластеризатор с embed–вектором) разделяет темы по направлениям (эпигенетика, метаболизм, иммунология, сенесценция и т.д.). Можно заранее определить набор категорий и сопоставить ключевые слова/NLP.
    3. **Оценка зрелости:** правилом: искать шаблоны в тексте («phase 2 trial», «mouse model», «FDA approved», «preclinical», «commercialization»), а также сверять с внешними базами (например, ClinicalTrials.gov API для поиска «найдено ли клиническое испытание по теме»). Чем выше этап (FDA или клиника) – тем выше уровень зрелости.
    4. **Оценка импакта:** комбинирует частоту упоминаний задачи, иментарность источников (импакт-фактор журнала, цитируемость, количество патентов) и тренды (рост публикаций по теме). Например, частоту за последний год можно считать временным взвешенным фактором. Можно обучить простую линейную модель, где фича «импакт-фактор» журнала и «число цитирований статьи» повышают вес темы. При наличии нескольких источников (наука+патенты) учитываются оба.
    5. **Ранжирование:** итоговый score = f(частота, IF, рост тенденции, патенты) комбинированная формула: например, $\text{score} = w_1\log(1+N_\text{sources}) + w_2\overline{\text{IF}} + w_3 \text{trend} + w_4\log(1+N_\text{patents}),$ где веса выбираются эмпирически. Или гибрид: LLM выдает приоритет в ответ на запрос о «самом перспективном направлении» с аргументацией.
  * *Инструменты:* LangChain (агенты/цепочки) для RAG-процесса, LlamaIndex или специализированные библиотеки для индексации EMB (чтобы быстро искать документы по теме). Библиотеки NLP: spaCy, scispaCy, HuggingFace Transformers. Для ранжирования – Python, scikit-learn (ранговые модели), простые правила на Python.

* **Агент «Генерация отчётов» (Reporting Agent):**

  * *Роль:* формирует текстовый отчёт по выбранной задаче.
  * *Вход:* одна приоритетная тема (или несколько) с метаданными: какие источники ее поддерживают, метрики (зрелость, импакт, confidence).
  * *Выход:* аргументированный текст (название задачи, обоснование, график/статистика, итоговый confidence, риски).
  * *Логика:* использует LLM (например, GPT-4, Mixtral или Llama 3) с цепочками промптов (LangChain LLMChain). В prompt подставляются: цитаты из источников, данные метрики (например, число публикаций), тренд-график (можно сделать график встроенно, а LLM получит ссылку или описание). LLM должен скомпоновать текст так, чтобы были явные ссылки на источники (например, «Smith et al. 2024 показали…»).
  * *Инструменты:* LangChain (LLMChain, PromptTemplate, OutputParser), возможен RAG (подача документов как контекста), LlamaIndex для дополнительных данных. Генерация графиков – matplotlib/Plotly (сохранить изображение и вставить в отчет).

**Варианты архитектуры:**

* *MVP (хакатон):* три агента по описанию. Монотонная очередь: агент 1 → агент 2 → агент 3. Простейший интерфейс (CLI или Telegram-бот). Все компоненты могут быть прототипированы с помощью скриптов Python, LangChain. Например, агент 1 – Python-скрипт c Biopython и requests; агент 2 – LangChain chains + LLM классификатор; агент 3 – LangChain SummarizeChain с закреплением ссылок.
* *Расширенный:* масштабируемая микросервисная архитектура. Микросервисы вместо простых агентов: например, сервис сбора (с гео- и многоязыковой фильтрацией), сервис NLP (распределённая очередь задач), сервис базы данных (PostgreSQL + векторная БД), сервис отчётов (генерация HTML с графикой). Добавляются новые языки (через автоматический перевод контекста перед обработкой) и новые области (модули для онкологии, нейродегенераций и т.д.). При этом все сервисы взаимодействуют по API (REST/gRPC) или через брокер сообщений (Kafka, RabbitMQ).

## Шаг 3: Сбор и обработка данных – мультисервисный парсер

Нужно реализовать модуль **универсального парсера** для разных источников, сохраняя результаты в общем формате (JSON). Предлагаемый JSON-формат:

```json
{
  "source": "PubMed",       // источник (PubMed, bioRxiv, USPTO, WIPO, WB, NewsAPI и т.д.)
  "type": "article",        // тип (article, preprint, patent, report, news)
  "id": "PMID:12345",       // уникальный идентификатор (PMID, DOI, patent_id)
  "title": "...",           // заголовок
  "abstract": "...",        // аннотация или текст
  "date": "2025-07-21",     // дата публикации
  "journal": "...",         // журнал/источник (если есть)
  "entities": ["senescence", "telomerase"], // ключевые понятия (генерируемые NER)
  "confidence": 0.85        // (опционально) оценка качества/релевантности
}
```

Для каждого источника:

* **PubMed:** использовать API NCBI Entrez (E-utilities). Например, `esearch.fcgi?db=pubmed&term=aging&retmode=json` вернёт список PMID. Затем `efetch.fcgi?db=pubmed&id=...&retmode=xml` для получения аннотации/метаданных. В Python удобно через Biopython: `Bio.Entrez.esearch/efetch`. Фильтры: по датам, типу «Journal Article», языку (англ.). Пример запроса:

  ```
  eutils.esearch?db=pubmed&term=(aging[Title/Abstract]+OR+longevity[Title/Abstract])+AND+humans[MeSH]+AND+English[lang]&retmax=100
  ```
* **bioRxiv:** официальный REST API `https://api.biorxiv.org/`. Можно брать `/details/biorxiv/<дата_начало>/<дата_конец>` или поиск по категории. Например, запрос `https://api.biorxiv.org/details/biorxiv/2023-01-01/2023-07-01/0` вернёт препринты за первое полугодие 2023 (поля DOI, title, abstract). Аналогично для medRxiv. Фильтровать по ключевым словам в заголовке или абстракте: можно запрашивать все и фильтровать локально по наличию «senescence», «epigenetic» и т.д. Для каждого препринта сохранять DOI, авторов, абстракт.
* **WIPO/USPTO (патенты):** использовать открытые API PatentsView (для США) или Lens/Patentscope. Например, к USPTO Open Data API:

  ```
  https://api.uspto.gov/patent/v3/application?searchText=aging&rows=50
  ```

  (псевдокод – подробности в документации USPTO). Для WIPO – Patentscope не имеет публичного API, но можно использовать Google Patents API (через Google Custom Search с \&tbm=pts, хотя есть ограничения). Альтернативно – Lens API (требует токен). Запросы: искать по классам IPC (например, `q=(ipc_class:(A61K OR C12N) AND (aging OR longevity))`), по датам, по ключевым словам. Из патента извлекать название, резюме, изобретателей, даты публикаций.
* **Открытые социально-экономические данные (World Bank, OECD, Our World in Data):** использовать их API или скачивать CSV. World Bank: API вида `https://api.worldbank.org/v2/country/all/indicator/SP.DYN.LE00.IN?date=2020:2025&format=json` (возвращает данные о продолжительности жизни, GDP и т.д.). OECD: база OECD.Stat с JSON API. Our World in Data (Github репозиторий) – в формате CSV (загрузить и парсить). Примеры фильтров: год публикации, регионы, интересующие индикаторы (life expectancy, health spending).
* **Новости и аналитика:** для Longevity.Technology, Lifespan.io – если есть RSS/JSON, иначе веб-скрейпинг. Можно пользоваться общими News API ([https://newsapi.org](https://newsapi.org)) или GDELT. Примеры запросов: `query="longevity OR anti-aging OR geroscience"`, фильтр по дате (последний месяц). Для MIT Tech Review – скрейпить категории Science/Health.
* **Неструктурированные данные:** получая PDF/HTML, использовать библиотеки: PyMuPDF или pdfminer для PDF, BeautifulSoup для HTML/XML. Извлекать текст, чистить (избавляться от реклам, боксов). Поиск сущностей и ключевых терминов в тексте (NER, регулярки).

После сбора, все данные приводятся к единому **JSON**-формату (см. выше). При сохранении можно добавлять поле `source_type` (исключая или уточняя, например, «pubmed\_journal», «pubmed\_preprint», «patent\_us», «patent\_wipo», «news”).

&#x20;*Пример конвейера обработки биомедицинских текстов (на основе подхода HALD): сначала выполняется сбор документов из PubMed и других источников, затем NER (PubTator, scispaCy) и извлечение отношений, после чего определяются ключевые сущности и темы для последующего анализа.*

## Шаг 4: Тематическая классификация и ранжирование

1. **Извлечение тем/задач:** полученные тексты (заголовки и абстракты) обрабатываются NLP-пайплайном. Сначала – удаление стоп-слов, лемматизация. Затем: NER (выделение генов, химических соединений, болезней с помощью scispaCy/PubTator) и частотный анализ терминов. Можно также использовать embedding (BioBERT, SciBERT, или Sentence Transformers) и кластеризацию: кластеры похожих документов дают темы. LLM (GPT-4) можно спросить напрямую: «Какие основные исследовательские задачи выделяются из этого списка статей?» и получить ответ, разбитый на пункты.
2. **Классификация по направлениям:** для каждой темы определяется область (эпигенетика, иммунология и т.д.). Это можно делать двумя способами: правилами (список ключевых слов по направлениям) и/или обученным классификатором (например, fine-tune LLM). Например, если в теме встречаются «теломеры», «метилирование» – это эпигенетика; «T-клетки», «цитокины» – иммунология.
3. **Уровень зрелости:** анализируем контекст публикаций. Правила: наличие слов «mouse model», «in vitro» → низкая зрелость; «phase 1/2 trial», «clinical study», «FDA approval» → высокая зрелость; «commercial product», «licensing deal» – готово к внедрению. Также сверяемся с ClinicalTrials.gov API: поиск термина темы в текущих испытаниях (если есть фазы, поднимается score зрелости). PatentsView API может подсказать комммерциализацию (наличие granted patents по теме).
4. **Потенциальный импакт:** считаем по совокупности влияния на здоровье и экономику. Например, высокая цитируемость и присутствие в открытых отчетах (Our World in Data) говорит о влиянии на здоровье; доля рынка препаратов (экономические отчеты) – на стоимость лечения. Для простоты можно вводить категории низкий/средний/высокий: например, «низкий», если тема пока только в препринтах и мышах; «средний» – есть клинические исследования; «высокий» – видны первые применяющиеся решения или лицензирование.
5. **Модель ранжирования:** гибридный подход:

   * **Векторные эмбеддинги:** индекс документов (LlamaIndex/Chroma) позволяет по запросу LLM получить релевантные выдержки.
   * **Правила:** как описано (условные паттерны, частотные пороги).
   * **LLM-оценка:** LLM (например, GPT-4) можно использовать для оценки приоритета: дать на вход текст описания темы и задать: «Оцените стратегическую важность этого направления от 1 (низко) до 5 (высоко)» с приложением фактов из текста.
     В качестве метрик: частота упоминаний темы в разных источниках, средний IF журналов, тренд количества публикаций (рост за 6 мес), число патентов в IPC-классах A61K/C12N (знак коммерциализации).

## Шаг 5: Модель оценки достоверности (confidence score)

Для каждой темы считаем **confidence\_score** как агрегатную метрику, отражающую, насколько надежны наши данные о ней. Компоненты:

* **Число подтверждающих источников:** чем больше независимых источников (статей, патентов, отчетов) указывают на тему – тем выше уверенность. Например, `score1 = log(1 + N_sources)`.
* **Разнообразие источников:** покрытия разных типов: научные (публикации), патенты, отчёты, новости. Баллы дают за наличие каждой категории. Больше разных типов → выше доверие (систематические обзоры + отраслевые новости vs только препринты).
* **Согласие между источниками:** проверяем наличие противоречивой информации. Если все источники сходятся (нет серьёзных опровержений или контрпримеров), добавляем очки. Для этого можно анализировать тональность и сигнатуру результатов: если одна работа говорит «нет эффекта», другая «да», уменьшаем score.
* **Качество данных:** весим источники по качеству: RCT исследования и peer-reviewed журналы выше, чем препринты или кейс-стади. Можно ввести вес: `weight = 1` для RCT/Nature/Lancet, `0.5` для препринтов и неглубоких отчётов, и суммировать. Например, `score2 = sum(weight_i)`.
* **Свежее время:** более новые публикации «важнее». Например, можно умножать вклад источника на `decay = exp(-λ*(current_year - pub_year))`, ставя λ так, чтобы статьи за год-два вносили больший вклад.

**Алгоритм агрегации:**
Общий confidence можно посчитать как взвешенную сумму и нормализацию, например:

```python
confidence = sigmoid(a*log(1+N_sources) + b*diversity + c*agreement + d*avg_quality + e*recency_factor)
```

где веса a…e настраиваются (можно задать эмпирически или калибровать). В результате формируется число от 0 до 1 (или шкала low/medium/high).

## Шаг 6: Генерация объяснённых отчётов

**Агент-аналитик** формирует текстовый отчёт для топовой темы. Структура отчёта:

* **Название темы/задачи.**
* **Обоснование выбора:** кратко – почему она приоритетна; указываем источники (например, «По данным статьи Smith et al. (2024) и патента US12345 представлены признаки прорывности…»).
* **Рост интереса:** мини-график (линия: число публикаций за последние 6 мес) или данные тренда.
* **Зрелость и импакт:** пишем «уровень зрелости X (научные термины/клиника/промышленные прототипы)» и «влияние оцениваем как Y (здоровье, качество жизни, экономия)».
* **Confidence score:** числовое или текстовое «высокий/средний/низкий» с объяснением (напр., «тема широко поддерживается 5 публикациями и 2 патентами (high confidence)»).
* **Риски/противоречия:** отмечаем, если есть, например, «рекомендации разнятся: одна группа считает это перспективным, другая – спорит» (генеративная часть LLM может выявить такие нюансы, если дать ему тексты разных источников).

Для генерации отчёта используем LLM (GPT-4, Mixtral, Llama 3) через LangChain:

* Берём ключевые факты: список цитат из источников (или сами тексты) + метрики (числа публикаций, IF, patents, confidence).
* Формируем промпт: «На основе данных источников \[вставляем выдержки] составь отчёт… с цитированием». Можно настроить LLM на стиль научного эссе.
* Если нужно больше контроля – сначала сгенерировать тезисы (chain-of-thought), потом итоговый текст.
  LangChain позволяет использовать **RAG**: собирать релевантные куски текстов к теме и давать их LLM для конструирования ответа. Также можно использовать Pinecone/Chroma для хранения векторов и извлекать контекст по запросу темы.

Важно обеспечить *научную корректность и объяснимость*:

* В ответ добавлять ссылки на номера PMID/DOI или патенты (формат \[Smith 2024] или непосредственно URL, если формат интерфейса это позволяет).
* Прокомментировать каждую точку: «(см. PubMed ID 12345678)».
* ЛЛМ должен использовать данные нейронного поиска, а не «галлюцинировать» факты. Методы: chaining + high temperature=низкая, а можно пост-обрабатывать генерацию и проверять упомянутые факты по API.

## Шаг 7: Визуализация и интерфейс

**Интерфейс:** минимально можно сделать **Telegram-бот** (часто лучшая UX в хакатон). Пример сценария: пользователь отправляет команду `/today`, бот высылает отчёт о приоритетной задаче за текущий день. Результат представлен в виде структурированного сообщения: **заголовок темы (жирным)**, краткий текст отчёта (с маркерами: «Уровень зрелости: …; Импакт: …; Confidence: …»), цитаты и ссылки под текстом, график активности (отображается как вложенное изображение).
Или Web-интерфейс (Streamlit/Gradio) с кнопкой «Show me today's priority» и обновляемый дашборд. В CLI – аналогично текст в консоль.

**Граф знаний/карта задач:** как дополнительный модуль. Строим **граф**, где узлы – ключевые темы/задачи, а рёбра – связи (общие патенты, перекрёстные цитирования, биологические связи). Цветовая кодировка: например, зрелость (синий – низкая, красный – высокая) и размер узла = impact. Инструменты: Neo4j (можно хранить всю сеть и строить запросы Cypher), D3.js (свободный drag-n-drop граф в web), или NetworkX+pyvis в Python. В веб можно вставить интерактивный граф (например, pyvis/Plotly Dash).

&#x20;*Пример – биомедицинские KG уже применяются для визуализации отношений между сущностями в геронтологии. В работе HALD показано, что «биомедицинский граф знаний может связывать биомедицинские сущности через отношения… что важно для понимания взаимосвязей» в данных о старении.* Это вдохновляет на аналогичную карту: узлы – темы (напр., «сенолитики», «теломеры»), рёбра – общие ключевые термины или цитируемость.

## Шаг 8: Тестовый датасет и фильтрация

**Создание тестового датасета:** собираем небольшой набор данных «из коробки» для демонстрации. Примеры:

* **PubMed-запросы:** используем MeSH и Title/Abstract. Например, `(aging[Title/Abstract] OR longevity[Title/Abstract]) AND English[lang] AND Journal Article[ptyp] AND humans[MeSH]`. Это даст статьи по старению. Аналогично запросы по «senescence», «NAD+», «epigenetic reprogramming». Для MeSH используем словарь из NCBI.
* **Патенты:** искать через PatentsView или Lens. Например, по IPC классам: `ipc_class:(A61K OR C12N) AND (aging OR longevity OR senescence)`. Можно загрузить несколько примеров (из Google Patents или Lens) с указанием поля «ипс», «описание».
* **Фильтрация нерелевантного:** исключаем статьи по материаловедению (“aging” = «возрастание материала») – отбрасываем по текстовым фильтрам (например, если только слово “aging” без биологического контекста). Удаляем статьи на других языках (если нужен только англ.).
* **Нормализация:** удаляем дубликаты (те же PMID или одинаковые DOI). Объединяем синонимы (например, «cellular senescence» = «клеточная старость»). Можно применить словарь синонимов (UMLS, PubMed Thesaurus) и корреляцию по embedding: если два заголовка имеют cosine >0.9, объединяем.

**Структура датасета:** можно сохранить в JSON или CSV. Например, CSV-поля: `id, source, title, abstract, date, entities, category`. Пример записи JSON (подробнее выше). Этот датасет будет небольшим, достаточным для демонстрации конвейера.

## Шаг 9: Валидация и демонстрация

* **Пример полного цикла:** показываем: агрегатор скачивает новую статью (скрипт или бот), агент 2 анализирует и формирует рейтинг тем, агент 3 генерирует отчёт. Например, за день система рекомендует «Cellular senescence: стратегия селективного удаления стареющих клеток». Пользователь видит краткий отчёт с цитатой «(Xie et al. 2024)» и графиком роста публикаций.
* **Проверка корректности:** сравниваем с обзорами и ключевыми публикациями 2023–2024. Например, Longevity Med Summit отмечал важность теломер и иммуносенесценции. Смотрим, вошли ли в наш топ темы «теломеры» и «иммунная старость», и совпадают ли наши обоснования с их описанием (теломеры – признак старения, immunosenescence/inflammaging – важный фактор). Это демонстрирует согласованность системы с экспертным мнением.
* **Прозрачность:** в демонстрации показываем экран (или сообщения) с *источниками*: под каждым утверждением бот указывает ссылки (например, PMID или URL). Показываем значение confidence (например, 0.82) и объясняем, почему оно такое (множественные источники, высокая IF). Это убедит зрителей в честности модели.
* **Демонстрация:** готовим слайды: схема архитектуры, пример вывода (скрин бота/веб), график знаний. Live-demo: запускаем систему на примере (в реальном времени или заранее закэшировано). За 5 минут показать: «/today → рекомендованная задача» с коротким пояснением и визуализацией.

## Шаг 10: Документирование архитектуры

В README/PDF описываем:

* **Диаграмму архитектуры:** можно в Mermaid или простым рисунком: три агента, источники, БД, интерфейс. Показать, как данные текут от сбора к отчёту.
* **Поток данных:** пояснение к диаграмме: Agent1→БД, Agent2→выдаёт темы→Agent3→генерит текст.
* **Стек технологий:** LangChain/CrewAI/LangGraph, Biopython, Pinecone/Chroma, Hugging Face, spaCy, NLTK, Flask/Streamlit или Python-telegram-bot, Neo4j/D3.js и т.д.
* **Масштабирование:** упомянуть легкость добавления новых агентов или источников (смоделированную через модульный дизайн). Как добавить другой язык: проводить перевод через Google Translate API или финетюнить модель на другом языке. Как расширить на области (заменить MeSH-термины, использовать другие IPК-классы для новых отраслей).
* **Ограничения:** честно написать, что пока система зависит от качества исходных данных и LLM, возможны неточности («галлюцинации» LLM), не все источники доступны без ключей (NewsAPI платный), требуются ресурсы для обновления.

## Стратегия победы (по критериям оценивания)

* **Обоснованность приоритезации:** даём полный учет цитат и метрик. Каждое утверждение обосновывается ссылкой. Это покажет, что рекомендации «не из воздуха».
* **Полнота источников:** на слайдах/демо подчеркнуть разнообразие: наглядно показать данные из PubMed, патентов, ВБ, новостей. Даже если данных мало, упомянуть хотя бы один пример из каждого типа (например, «Анализ экономических отчётов World Bank показывает…»).
* **Прозрачность:** в UI/отчете выводить *все* источники и расчёты метрик. Например, после текста отчёта бот может прикладывать текст: «Найдено 5 статей, 2 патента, всё подтверждает тему» и список ссылок. Показываем значение confidence и его составляющие (например, график или табличку).
* **UX:** запоминающийся UI – Telegram-бот с push-уведомлением `/today` без лишних сложностей. Хорошим бонусом будут регулярные оповещения (например, каждый день в 9 утра) или кнопки «Получить полную сводку». Использовать форматированное сообщение с эмодзи, разделителями, встроенными ссылками для улучшения восприятия.
* **Масштабируемость:** в презентации упомянуть, как система легко переориентируется: достаточно поменять список ключевых слов и источников. Например, модуль сбора может взять PubMed на другом языке (русскоязычные публикации), модуль классификации – переключиться на задачи онкологии. В README сделать сноску: «для другой области (напр. нейродегенерации) достаточно заменить MeSH-термины и IPC-классы».

## Источники и инструменты

* **API и источники данных:** PubMed (NCBI Entrez API), bioRxiv API, USPTO PatentsView / WIPO Patentscope (Lens API), Google Patents (поиск `tbm=pts`), NewsAPI (новости), World Bank/UN Data (API/CSV).
* **Языки и фреймворки:** Python (requests, BeautifulSoup, Biopython), LangChain / CrewAI / LangGraph / AutoGPT для агентной логики, LlamaIndex или Pinecone/Chroma для векторных запросов.
* **LLM:** OpenAI GPT-4, Mixtral (бесплатный), Llama 3 (open-source) — как генераторы текста и анализаторы контекста.
* **NLP-библиотеки:** spaCy, scispaCy (NER для биомедицины), HuggingFace Transformers (BERT, BioBERT, T5), NLTK.
* **Ранги/матрицы:** scikit-learn (ранговая регрессия), pandas/numpy для подсчётов, SQL/NoSQL БД.
* **Визуализация:** Streamlit или Gradio для интерфейса, Telegram Bot API. Для графов: Neo4j или NetworkX+pyvis/D3.js/Plotly Dash. Matplotlib/Plotly для построения временных графиков.
* **Другие:** PubTator API (бот для аннотаций), Google Translate API (для мультиязычности), Docker для контейнеризации, GitHub Actions (CI/CD), Mermaid для диаграмм в документации.
